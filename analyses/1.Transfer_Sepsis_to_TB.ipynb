{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Sepsis to TB\n",
    "This notebook looks at whether a model trained on sepsis data learns anything about how to classify tuberculosis data. Both the sepsis and TB samples are a combination of whole blood microarrays and RNA-seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse                                                                                     \n",
    "import logging                                                                                      \n",
    "import numpy as np \n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add whistl modules to the path\n",
    "sys.path.append('../whistl')\n",
    "import classifier\n",
    "import dataset\n",
    "import model\n",
    "import plot_util\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell pytorch to use the gpu\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)                                                         \n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the models train deterministically\n",
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)                                                                       \n",
    "random.seed(seed)                                                                          \n",
    "torch.manual_seed(seed)                                                                    \n",
    "if torch.backends.cudnn.enabled:                                                                \n",
    "    torch.backends.cudnn.deterministic = True                                                   \n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models on sepsis using ERM and IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arguments to use in training the models\n",
    "map_file = '../data/sample_classifications.pkl'\n",
    "gene_file = '../data/intersection_genes.csv'\n",
    "num_epochs = 1500\n",
    "loss_scaling_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a classifier architecture\n",
    "label_to_encoding = {'sepsis': 1, 'healthy': 0}\n",
    "sample_to_label = util.parse_map_file(map_file)\n",
    "\n",
    "net = model.ThreeLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "\n",
    "data_dirs = util.get_data_dirs('../data')                                                      \n",
    "train_dirs, test_dirs = util.extract_test_dirs(data_dirs, 'tb', sample_to_label)                                               \n",
    "\n",
    "train_dirs, tune_dirs = util.train_tune_split(train_dirs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139e8fa8a1bd4621b8891c8741e66223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "erm_results = classifier.train_with_erm(net, map_file, train_dirs, tune_dirs, gene_file, num_epochs, \n",
    "                                        label_to_encoding, device, logger, '../logs/sepsis_erm.pkl', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b55be89fa8b42239830d330c5776bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "irm_results = classifier.train_with_irm(net, map_file, train_dirs, tune_dirs, gene_file, num_epochs, \n",
    "                                        loss_scaling_factor, label_to_encoding, device, logger, '../logs/sepsis_irm.pkl', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print tuning set accuracy at the end of training for ERM and IRM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9459459459459459, 0.9459459459459459, 0.8918918918918919, 0.9459459459459459, 0.9054054054054054]\n"
     ]
    }
   ],
   "source": [
    "print(erm_results['tune_acc'][-5:])\n",
    "print(irm_results['tune_acc'][-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models on tuberculosis samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the disease encoding\n",
    "label_to_encoding = {'tb': 1, 'healthy': 0}                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tuberculosis data\n",
    "tb_dataset = dataset.ExpressionDataset(test_dirs, sample_to_label, label_to_encoding, gene_file)\n",
    "tb_loader = torch.utils.data.DataLoader(tb_dataset, batch_size=16, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate erm and irm models on tb set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "erm_net = torch.load('../logs/sepsis_erm.pkl')\n",
    "irm_net = torch.load('../logs/sepsis_irm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "erm_loss = 0\n",
    "erm_correct = 0\n",
    "irm_loss = 0\n",
    "irm_correct = 0\n",
    "\n",
    "erm_tb_preds= 0\n",
    "irm_tb_preds = 0\n",
    "\n",
    "\n",
    "for tb_batch in tb_loader:\n",
    "    expression, labels, ids = tb_batch                                            \n",
    "    tune_expression = expression.to(device)                                         \n",
    "    tune_labels = labels.to(device).double()                                        \n",
    "\n",
    "    loss_function = torch.nn.BCEWithLogitsLoss()                                          \n",
    "\n",
    "    erm_preds = erm_net(tune_expression)\n",
    "    loss = loss_function(erm_preds, tune_labels)\n",
    "    erm_loss += float(loss)\n",
    "    erm_correct += util.count_correct(erm_preds, tune_labels)\n",
    "    \n",
    "    irm_preds = irm_net(tune_expression)      \n",
    "    loss = loss_function(irm_preds, tune_labels)\n",
    "    irm_loss += float(loss)\n",
    "    irm_correct += util.count_correct(irm_preds, tune_labels)\n",
    "    \n",
    "    # Count how many times the model predicted something other than zero\n",
    "    erm_tb_preds += np.sum(erm_preds.cpu().detach().numpy() >= 0)\n",
    "    irm_tb_preds += np.sum(irm_preds.cpu().detach().numpy() >= 0)\n",
    "    \n",
    "avg_erm_loss = erm_loss / len(tb_dataset)\n",
    "erm_acc = erm_correct / len(tb_dataset)\n",
    "avg_irm_loss = irm_loss / len(tb_dataset)\n",
    "irm_acc = irm_correct / len(tb_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n",
      "520\n",
      "907\n"
     ]
    }
   ],
   "source": [
    "print(erm_tb_preds)\n",
    "print(irm_tb_preds)\n",
    "print(len(tb_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM trained network tb accuracy: 0.7375964718853363\n",
      "ERM trained network tb loss: 0.06897230209944204\n",
      "IRM trained network tb accuracy: 0.6008820286659317\n",
      "IRM trained network tb loss: 0.04761558565200637\n"
     ]
    }
   ],
   "source": [
    "print('ERM trained network tb accuracy: {}'.format(erm_acc))\n",
    "print('ERM trained network tb loss: {}'.format(avg_erm_loss))\n",
    "print('IRM trained network tb accuracy: {}'.format(irm_acc))\n",
    "print('IRM trained network tb loss: {}'.format(avg_irm_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find percent healthy\n",
    "Our base rate is the percentage of healthy samples in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prercent healthy = 0.23042998897464168\n"
     ]
    }
   ],
   "source": [
    "total_healthy = 0\n",
    "for test_batch in tb_loader:\n",
    "    expression, labels, ids = test_batch\n",
    "    for label in labels:\n",
    "        if label == label_to_encoding['healthy']:\n",
    "            total_healthy += 1\n",
    "\n",
    "print('Prercent healthy = {}'.format(total_healthy / len(tb_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logs/sepsis_erm_results.pkl', 'wb') as out_file:\n",
    "    pickle.dump(erm_results, out_file)\n",
    "with open('../logs/sepsis_irm_results.pkl', 'wb') as out_file:\n",
    "    pickle.dump(irm_results, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "While they don't perform as well on the transferred domain as the source domain, both the erm and irm trained networks have better than random (and better than the frequency of the more common class). Interestingly, the ERM trained model predicted tuberculosis 8/9 of the time, while the IRM trained model predicted tb about 5/9 of the time. The true frequency of tb in the dataset is 77%.\n",
    "\n",
    "These results are evidence that domain adaptation works to some extent on gene expression data even between diseases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whistl",
   "language": "python",
   "name": "whistl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
