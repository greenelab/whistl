{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Saving\n",
    "This notebook is designed to make sure saving and loading models works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse                                                                                     \n",
    "import logging                                                                                      \n",
    "import numpy as np   \n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add whistl modules to the path\n",
    "sys.path.append('../whistl')\n",
    "import classifier\n",
    "import dataset\n",
    "import model\n",
    "import plot_util\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell pytorch to use the gpu\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)                                                         \n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the models train deterministically\n",
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)                                                                       \n",
    "random.seed(seed)                                                                          \n",
    "torch.manual_seed(seed)                                                                    \n",
    "if torch.backends.cudnn.enabled:                                                                \n",
    "    torch.backends.cudnn.deterministic = True                                                   \n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a classifier architecture\n",
    "label_to_encoding = {'tb': 1, 'healthy': 0}                                                 \n",
    "net = model.ThreeLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "train_dirs, tune_dirs = util.train_tune_split('../data/', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arguments to use in training the models\n",
    "map_file = '../data/sample_classifications.pkl'\n",
    "gene_file = '../data/intersection_genes.csv'\n",
    "num_epochs = 1500\n",
    "loss_scaling_factor = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a three layer neural network with IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a1221e0db94708a09c0a0833ad9fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "irm_results = classifier.train_with_irm(net, map_file, train_dirs, tune_dirs, gene_file, num_epochs, \n",
    "                                        loss_scaling_factor, label_to_encoding, device, logger, '../logs/irm.pkl', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and ensure the weights saved properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_net = torch.load('../logs/irm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_label = util.parse_map_file(map_file)\n",
    "\n",
    "tune_dataset = dataset.ExpressionDataset(tune_dirs, sample_to_label, label_to_encoding, gene_file)\n",
    "tune_loader = torch.utils.data.DataLoader(tune_dataset, batch_size=16, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_loss = 0\n",
    "tune_correct = 0\n",
    "\n",
    "for tune_batch in tune_loader:\n",
    "    expression, labels, ids = tune_batch                                            \n",
    "    tune_expression = expression.to(device)                                         \n",
    "    tune_labels = labels.to(device).double()                                        \n",
    "\n",
    "    loss_function = torch.nn.BCEWithLogitsLoss()                                          \n",
    "\n",
    "    tune_preds = trained_net(tune_expression)                                        \n",
    "    loss = loss_function(tune_preds, tune_labels)\n",
    "    \n",
    "    tune_loss += float(loss)\n",
    "    tune_correct += util.count_correct(tune_preds, tune_labels)\n",
    "    \n",
    "avg_loss = tune_loss / len(tune_dataset)\n",
    "tune_acc = tune_correct / len(tune_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained network tune accuracy: 1.0\n",
      "Trained network tune loss: 5.13992141030165e-19\n"
     ]
    }
   ],
   "source": [
    "print('Trained network tune accuracy: {}'.format(tune_acc))\n",
    "print('Trained network tune loss: {}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test untrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = tune_dataset[0][0].shape[0]\n",
    "untrained_net = model.ThreeLayerNet(input_size).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_loss = 0\n",
    "tune_correct = 0\n",
    "\n",
    "for tune_batch in tune_loader:\n",
    "    expression, labels, ids = tune_batch                                            \n",
    "    tune_expression = expression.to(device)                                         \n",
    "    tune_labels = labels.to(device).double()                                        \n",
    "\n",
    "    loss_function = torch.nn.BCEWithLogitsLoss()                                          \n",
    "\n",
    "    tune_preds = untrained_net(tune_expression)                                        \n",
    "    loss = loss_function(tune_preds, tune_labels)\n",
    "    \n",
    "    tune_loss += float(loss)\n",
    "    tune_correct += util.count_correct(tune_preds, tune_labels)\n",
    "    \n",
    "avg_loss = tune_loss / len(tune_dataset)\n",
    "tune_acc = tune_correct / len(tune_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained network tune accuracy: 0.0\n",
      "Untrained network tune loss: 0.0527816792333729\n"
     ]
    }
   ],
   "source": [
    "print('Untrained network tune accuracy: {}'.format(tune_acc))\n",
    "print('Untrained network tune loss: {}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to a file to keep track of genes and samples used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logs/model_saving_test_results.pkl', 'wb') as out_file:\n",
    "    pickle.dump(irm_results, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The model saving functions in `classifier.py` work, and the trained network outperforms an untrained one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whistl",
   "language": "python",
   "name": "whistl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
